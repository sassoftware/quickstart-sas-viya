---
AWSTemplateFormatVersion: 2010-09-09
Description: >-
  This template deploys a SAS Viya stack.
  **WARNING** This template creates EC2 instances and related resources. You
  will be billed for the AWS resources used if you create a stack from this
  template. License: Apache 2.0 (Please do not remove) Apr,19,2018 (qs-1ocb9ttqc)
Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: SAS Viya License and Install Package
        Parameters:
          - DeploymentDataLocation
      - Label:
          default: Administration
        Parameters:
          - KeyPairName
          - WebIngressLocation
          - AdminIngressLocation
          - SASAdminPass
          - SASUserPass
#          - CASInstanceType
#          - DeploymentMirror
          - OperatorEmail
      - Label:
          default: Network Configuration
        Parameters:
          - VPCID
          - PublicSubnetID
          - PrivateSubnetID
      - Label:
          default: Server DNS configuration (only required for custom DNS name and SSL)
        Parameters:
          - DomainName
          - AWSHostedZoneID
          - SSLCertificateARN
      - Label:
          default: AWS Quick Start Source Location
        Parameters:
          - QSS3BucketName
          - QSS3KeyPrefix

    ParameterLabels:
      KeyPairName:
        default: Key Name
      PrivateSubnetID:
        default: Private Subnet ID
      PublicSubnetID:
        default: Public Subnet ID
      QSS3BucketName:
        default: Quick Start S3 Bucket Name
      QSS3KeyPrefix:
        default: Quick Start S3 Key Prefix
      DeploymentDataLocation:
        default: SAS Viya Software Order File
#      CASInstanceType:
#        default: EC2 Instance Type for the CAS compute VM
      VPCID:
        default: VPC ID
      AdminIngressLocation:
        default: Permitted IP Range for Deployment Administrator
      WebIngressLocation:
        default: Permitted IP Range for Application Access
      SASAdminPass:
        default: SAS Administrator Password
      SASUserPass:
        default: Password for Default User
#      DeploymentMirror:
#        default: Mirror of SAS Viya Deployment Data
      OperatorEmail:
        default: Operator Email
      SSLCertificateARN:
        default: SSL Certificate
      DomainName:
        default: Domain Name
      AWSHostedZoneID:
        default: Route 53 Hosted Zone

Parameters:

  DeploymentDataLocation:
    AllowedPattern: >-
      ^([-a-zA-Z0-9@:%_\+.~#?&//=]*)\.zip$
    Description: >-
      S3 location of the Software Order Confirmation e-mail attachment.
      Example: mysasbucket/viya_deployment_data/SAS_Viya_deployment_data.zip
    Type: String
    MinLength: '1'
    ConstraintDescription: must be a zip file in a valid S3 bucket location, e.g. mysasbucket/viya_deployment_data/SAS_Viya_deployment_data.zip
#  CASInstanceType:
#    AllowedValues:
#      - "i3"
#      - "r4"
#    ConstraintDescription: Must contain either "i3" or "r4"
#    Default: "i3"
#    Description: Type of EC2 instance for the Viya Compute Nodes (i3 for performance, r4 for auto-recovery)
#    Type: String



  KeyPairName:
    Description: >-
      Name of an existing EC2 key pair. This will allow you to access the Ansible Controller after it launches.
    Type: AWS::EC2::KeyPair::KeyName
    MinLength: '1'
    ConstraintDescription: must be a existing AWS Key Pair name current AWS region.
  WebIngressLocation:
      Description: >-
        Allow inbound HTTP traffic to the SAS Viya Environment from this CIDR block (IP address range). Must be a valid IP CIDR range of the form x.x.x.x/x.
      Type: String
      MinLength: '9'
      MaxLength: '18'
      AllowedPattern: ^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\/([0-9]|[1-2][0-9]|3[0-2]))$
      ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x.
  AdminIngressLocation:
    Description: >-
      Allow inbound SSH traffic to the Ansible Controller from this CIDR block (IP address range). Must be a valid IP CIDR range of the form x.x.x.x/x.
    Type: String
    MinLength: '9'
    MaxLength: '18'
    AllowedPattern: ^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\/([0-9]|[1-2][0-9]|3[0-2]))$
    ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x.


  SASAdminPass:
    Description: >-
      Password of the SAS Admin Users (sasboot, optionally sasadmin). Must have at least 6 and no more than 255 characters.
    Type: String
    MinLength: '6'
    MaxLength: '255'
    NoEcho: true
    AllowedPattern: ^([^']*)$
    ConstraintDescription: Password must have at least 6 and no more than 255 characters and cannot contain single quotes.
  SASUserPass:
    Description: >-
      Password of the default SAS User (sasuser). If left empty, no default users are being created (WARNING: If not set, deployment will require additional setup steps before being usable).
    Type: String
    MaxLength: '255'
    NoEcho: true
    AllowedPattern: ^([^']*)$
    ConstraintDescription: Password cannot be longer than 255 characters and cannot contain single quotes.

#  DeploymentMirror:
#    Description: >-
#      (Optional) Location of SAS Viya Deployment Repository Mirror
#    Default: ''
#    Type: String
#    ConstraintDescription: must be valid http(s) or s3 location of mirror repository (e.g. https://my-repository-vm or s3://my-bucket/my-path)
#    AllowedPattern: ^(^$|s3:\/\/|(http|https):\/\/).*


  VPCID:
    Description: ID of an existing VPC with a public and a private subnet in the same Availability Zone.
    Type: AWS::EC2::VPC::Id
    MinLength: '12'
    MaxLength: '21'
    ConstraintDescription: must be an existing VPC ID in the current AWS region
  PublicSubnetID:
    Description: >-
      ID of public subnet for the Elastic Load Balancer
      and Ansible Controller (e.g. subnet-1234567890abcdef0)
      (must be in the same AZ as PrivateSubnetID)
    Type: AWS::EC2::Subnet::Id
    MinLength: '15'
    MaxLength: '24'
    ConstraintDescription: must be an existing Subnet ID in the current AWS region
  PrivateSubnetID:
    Description: >-
      ID of private subnet for the SAS Viya Application VMs (e.g. subnet-1234567890abcdef0)
      (must be in the same AZ as PublicSubnetID)
    Type: AWS::EC2::Subnet::Id
    MinLength: '15'
    MaxLength: '24'
    ConstraintDescription: must be an existing Subnet ID in the current AWS region

  QSS3BucketName:
    AllowedPattern: ^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$
    ConstraintDescription: >-
      Quick Start bucket name can include numbers, lowercase letters, uppercase
      letters, and hyphens (-). It cannot start or end with a hyphen (-).
    Default: aws-quickstart
    Description: >-
     S3 bucket name for the Quick Start assets.
     Only change this value if you customize or extend the Quick Start for your own use.
     This string can include numbers, lowercase letters, uppercase letters, and hyphens (-).
     It cannot start or end with a hyphen (-).
    Type: String
  QSS3KeyPrefix:
    AllowedPattern: ^[0-9a-zA-Z-/]*[/]$
    ConstraintDescription: >-
      Quick Start key prefix can include numbers, lowercase letters, uppercase
      letters, hyphens (-), and forward slash (/) and must terminate in a forward slash.
    Default: quickstart-sas-viya/
    Description: >-
      S3 key prefix for the Quick Start assets.
      Only change this value if you customize or extend the Quick Start for your own use.
      Quick Start key prefix can include numbers, lowercase letters, uppercase letters, hyphens (-),
      and forward slash (/) and must terminate in a forward slash.
    Type: String
  OperatorEmail:
    AllowedPattern: "([a-zA-Z0-9_\\-\\.]+)@((\\[[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.)|(([a-zA-Z0-9\\-]+\\.)+))([a-zA-Z]{2,4}|[0-9]{1,3})(\\]?)|^$"
    ConstraintDescription: must be a valid email address.
    Description: Email address to send a notification about deployment success or failure (optional).
    Type: String
    Default: ''


  SSLCertificateARN:
    Description: >-
      The AWS CertificateManager Amazon Resource Name (ARN) for the SSL certificate to use to enable HTTPS. The certificate needs to match the DomainName.
      Syntax: arn:aws:acm:region:account-id:certificate/certificate-id
      Example: arn:aws:acm:us-east-1:123456789012:certificate/12345678-1234-1234-1234-123456789012
    Type: String
    Default: ''
  DomainName:
    Description: The SAS Viya Server portal will be reachable at this DNS name (blank = generated ELB name will be used as application DNS name)
    Type: String
    Default: ''
  AWSHostedZoneID:
    Description: Existing DNS Zone ID for the DomainName (blank = generated ELB name will be used as application DNS name)
    Type: String
    Default: ''

Mappings:
  AWSAMIRegionMap:
    AMI:
      AMZNLINUXHVM: amzn-ami-hvm-2017.09.1.20180115-x86_64-gp2
      RHEL74HVM: RHEL-7.4_HVM-20180122-x86_64-1-Hourly2-GP2
    ap-northeast-1:
      AMZNLINUXHVM: ami-ceafcba8
      RHEL74HVM: ami-36f09350
    ap-northeast-2:
      AMZNLINUXHVM: ami-863090e8
      RHEL74HVM: ami-90a201fe
    ap-south-1:
      AMZNLINUXHVM: ami-531a4c3c
      RHEL74HVM: ami-5c2f7e33
    ap-southeast-1:
      AMZNLINUXHVM: ami-68097514
      RHEL74HVM: ami-8d90e9f1
    ap-southeast-2:
      AMZNLINUXHVM: ami-942dd1f6
      RHEL74HVM: ami-e1996783
    ca-central-1:
      AMZNLINUXHVM: ami-a954d1cd
      RHEL74HVM: ami-71018415
    eu-central-1:
      AMZNLINUXHVM: ami-5652ce39
      RHEL74HVM: ami-8a21bfe5
    eu-west-1:
      AMZNLINUXHVM: ami-d834aba1
      RHEL74HVM: ami-ccb7d2b5
    eu-west-2:
      AMZNLINUXHVM: ami-403e2524
      RHEL74HVM: ami-b4b3a8d0
    eu-west-3:
      AMZNLINUXHVM: ami-8ee056f3
      RHEL74HVM: ami-66d0661b
    sa-east-1:
      AMZNLINUXHVM: ami-84175ae8
      RHEL74HVM: ami-1a064a76
    us-east-1:
      AMZNLINUXHVM: ami-97785bed
      RHEL74HVM: ami-76a3970c
    us-east-2:
      AMZNLINUXHVM: ami-f63b1193
      RHEL74HVM: ami-cebe94ab
    us-west-1:
      AMZNLINUXHVM: ami-824c4ee2
      RHEL74HVM: ami-c8020fa8
    us-west-2:
      AMZNLINUXHVM: ami-f2d3638a
      RHEL74HVM: ami-1607ba6e
  LinuxAMINameMap:
    RHEL-7.4-HVM:
      Code: RHEL74HVM
    Amazon-Linux-HVM:
      Code: AMZNLINUXHVM


Rules:
  KeyPairsNotEmpty:
    Assertions:
      - Assert: !Not
          - Fn::EachMemberEquals:
              - Fn::RefAll: AWS::EC2::KeyPair::KeyName
              - ''
        AssertDescription: All key pair parameters must not be empty
  SubnetsInVPC:
    Assertions:
      - Assert:
          Fn::EachMemberIn:
            - Fn::ValueOfAll:
                - AWS::EC2::Subnet::Id
                - VpcId
            - Fn::RefAll: AWS::EC2::VPC::Id
        AssertDescription: All subnets must in the VPC
  SubnetsInSameAZ:
    Assertions:
      - Assert:
          Fn::Equals:
            - Fn::ValueOf:
              - PublicSubnetID
              - AvailabilityZone
            - Fn::ValueOf:
              - PrivateSubnetID
              - AvailabilityZone
        AssertDescription: Public and Private subnet must in the same AZ
  DomainNameWithHostedZone:
    Assertions:
      - Assert:
          Fn::Or:
          - Fn::And:
            - !Equals
              - !Ref DomainName
              - ''
            - !Equals
              - !Ref AWSHostedZoneID
              - ''
          - Fn::And:
            - !Not
              - !Equals
                - !Ref DomainName
                - ''
            - !Not
              - !Equals
                - !Ref AWSHostedZoneID
                - ''
        AssertDescription: DomainName and AWSHostedZoneID need to be set together

Conditions:
  GovCloudCondition: !Equals
    - !Ref AWS::Region
    - us-gov-west-1
  SNSCondition: !Not
    - !Equals
      - !Ref OperatorEmail
      - ''

#  IsI3: !Equals
#    - !Ref CASInstanceType
#    - i3

#  IsNotI3:
#    Fn::Not:
#    - Condition: IsI3

  NoDNSEntry:
    Fn::Or:
    - Fn::Equals:
      - ''
      - Ref: AWSHostedZoneID
    - Fn::Equals:
      - ''
      - Ref: DomainName
  HasDNSEntry:
    Fn::Not:
    - Condition: NoDNSEntry
  NoSSLCertificate:
    Fn::Equals:
    - ''
    - Ref: SSLCertificateARN
  HasSSLCertificate:
    Fn::Not:
    - Condition: NoSSLCertificate


Resources:

  # Lambda Function that scans the license file for the CAS cpu count
  # and returns instance sizes and counts
  LicenseFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          import zipfile
          import boto3
          from urllib.parse import urlparse
          import io
          from botocore.vendored import requests
          import json
          SUCCESS = "SUCCESS"
          FAILED = "FAILED"
          rD = {}
          rS = FAILED
          s3 = boto3.client('s3')
          def license(event, context):
            # rD["s3_mirror_bucket"] = ''
            # rD["s3_mirror_path"] = ''
            # deployment_mirror_path = event['ResourceProperties']['DeploymentMirror']
            #if (deployment_mirror_path.lower().startswith('s3')):
            #  o = urlparse(deployment_mirror_path)
            #  rD["s3_mirror_bucket"] = o.netloc
            #  rD["s3_mirror_path"] = o.path
            ddl = event['ResourceProperties']['DeploymentDataLocation']
            bucket = ddl[:ddl.find('/')]
            key = ddl[ddl.find('/')+1:]
            try:
              obj = s3.get_object(Bucket=bucket, Key=key)
            except Exception as e:
              rS = FAILED
              reason = 'DeploymentDataLocation ' + event['ResourceProperties']['DeploymentDataLocation'] +  ' is not accessible.'
              send(event, context, rS, rD, reason)
            with io.BytesIO(obj["Body"].read()) as tf:
              tf.seek(0)
              rD['ViyaVersion'] = '3.3'
              rD['SASHomePath'] = '/SASHome'
              rD['SASStudioPath'] = '/SASStudio'
              with zipfile.ZipFile(tf, mode='r') as zipf:
                for file in zipf.infolist():
                  if (file.filename.endswith('Linux_x86-64.txt')):
                    templicensefile = zipf.extract(file,'/tmp')
                  if (file.filename.endswith('.jwt')):
                    rD['ViyaVersion'] = '3.4'
                    rD['SASHomePath'] = '/SASDrive'
                    rD['SASStudioPath'] = '/SASStudioV'
              tline = ''
              lf = []
              with open(templicensefile) as tlf:
                for line in tlf:
                  tline = tline + line
                  if ';' in line:
                    lf.append(tline)
                    tline = ''
              for row in lf:
                if 'EXPIRE' in row:
                  if 'PRODNUM1141' in row:
                    prodnum = row
              if prodnum is None:
                raise ValueError('The CAS product number was not found in the license file.')
              cascpu = prodnum[prodnum.find('CPU=')+4:prodnum.find(';')]
              if cascpu is None:
                raise ValueError('The CASCPU number was not found in the license file.')
              for row in lf:
                if "NAME="+cascpu in row:
                  model = row
              if model is None:
                raise ValueError('The CPU detail row for the CAS cpu was not found in the license file.')
              cpucount = int(model[model.find('SERIAL=')+9:][:3].replace("'",""))
              if cpucount == 999:
                cpucount = int(4)
                if ddl.find("Core") > 0:
                  cpucount = int(ddl[ddl.find("Core")-2:ddl.find("Core")].strip('_'))
              rD['CPUCount'] = cpucount
              rS = SUCCESS

            rD["NumWorkers"] = 0
            rD["CASLibSize"] = 500
            rD["UserLibSize"] = 500
            rD["NodeInstanceSize"] = "2xlarge"
            rD["CASCacheSize"] = 180
            if cpucount == 4:
              pass
            elif cpucount <= 8:
              rD["NodeInstanceSize"] = "4xlarge"
              rD["CASCacheSize"] = 360
            elif cpucount <= 16:
              rD["NodeInstanceSize"] = "8xlarge"
              rD["CASLibSize"] = 1000
              rD["UserLibSize"] = 1000
              rD["CASCacheSize"] = 720
            else:
              rS = FAILED
              print("Invalid Licensed CPU Count: {0}".format(cpucount))
            send(event, context, rS, rD)
          def send(event, context, rS, rD, reason="", physicalResourceId=None, noEcho=False):
            responseUrl = event['ResponseURL']

            print (responseUrl)
            if reason == "":
              reason = 'See the details in CloudWatch Log Stream: ' + context.log_stream_name
            rB = {}
            rB['Status'] = rS
            rB['Reason'] = reason
            rB['PhysicalResourceId'] = physicalResourceId or context.log_stream_name
            rB['StackId'] = event['StackId']
            rB['RequestId'] = event['RequestId']
            rB['LogicalResourceId'] = event['LogicalResourceId']
            rB['NoEcho'] = noEcho
            rB['Data'] = rD

            json_rB = json.dumps(rB)

            print ("Response body:\n" + json_rB)

            headers = {
                'content-type' : '',
                'content-length' : str(len(json_rB))
            }

            try:
                response = requests.put(responseUrl,
                                        data=json_rB,
                                        headers=headers)
                print ("Status code: " + response.reason)
            except Exception as e:
                print ("send(..) failed executing requests.put(..): " + str(e))
      Handler: index.license
      Runtime: python3.6
      Timeout: 30
      Role: !GetAtt LicenseLambdaExecutionRole.Arn
      Description: !Sub LicenseInfo Custom Property for Stack ${AWS::StackName}
  LicenseLambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: "/"
      Policies:
      - PolicyName: root
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - logs:CreateLogStream
            - logs:PutLogEvents
            Resource: arn:aws:logs:*:*:*
          - Effect: Allow
            Action:
            - s3:getObject
            Resource: !Sub 'arn:aws:s3:::${DeploymentDataLocation}'
          - Effect: Allow
            Action:
            - s3:GetBucketLocation
            Resource: !Sub
              - 'arn:aws:s3:::${target_bucket_name}'
              - {target_bucket_name: !Select [0, !Split [ '/', !Sub "${DeploymentDataLocation}" ] ] }
  # create the log Group for Lambda by Cloudformation to ensure
  # it is deleted at termination
  LicenseLambdaFunctionLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub /aws/lambda/${LicenseFunction}
  # Custom Property to determine deployment size
  LicenseInfo:
    Type: Custom::LicenseInfo
    Properties:
      ServiceToken: !GetAtt LicenseFunction.Arn
      DeploymentDataLocation: !Ref DeploymentDataLocation
      IsPublic: !GetAtt IsLicensePublicInfo.is_public
      # DeploymentMirror: !Ref DeploymentMirror

  # Lambda Function that checks the license file to see if it can be publicly downloaded
  IsLicensePublicFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          import boto3
          import urllib.request
          from botocore.vendored import requests
          import json
          def is_license_public(event, context):

            is_public = False
            license_file_path = event['ResourceProperties']['DeploymentDataLocation']
            bucket_name = license_file_path.split("/")[0]
            try:
              s3_client = boto3.client("s3")
              location_response = s3_client.get_bucket_location(Bucket=bucket_name)
            except:
              # in case we cannot establish the the bucket location, we return a positive result
              # An error here could be caused by any of these:
              # - the bucket does not exist (an error with then be caught by LicenseFunction)
              # - bucket not accessible (error later caught by LicenseFunction)
              # - The bucket is in a different account and GetBucketLocation permission not set for client account
              #   - this can be due to missing permissions on the bucket or the role
              #   - or in this edge case: the bucket is in a different account and a different region than
              #     the client session. Even setting explicit permissions for GetBucketLoccation will not suffice.
              is_public = False
            else:
              location = location_response['LocationConstraint']
              if location is None:
                location = 'us-east-1'
              s3_location_client = boto3.client('s3', region_name=location)
              url_accessable = True
              url = '{}/{}'.format(s3_location_client.meta.endpoint_url, license_file_path)
              try:
                response = urllib.request.urlopen(url)
                is_public = True
              except urllib.error.HTTPError as e:
                if e.code == 403:
                  is_public = False
                else:
                  raise e

            if is_public:
              send(event, context, "FAILED", {'is_public': is_public}, 'License File at ' + license_file_path + ' is public and can be accessed by anyone. Please secure this file before proceeding.')
            else:
              send(event, context, "SUCCESS", {'is_public': is_public}, 'License File at ' + license_file_path + ' is private.')
            return is_public
          def send(event, context, rS, rD, reason="", physicalResourceId=None, noEcho=False):
            responseUrl = event['ResponseURL']
            print(responseUrl)
            if reason == "":
              reason = 'See the details in CloudWatch Log Stream: ' + context.log_stream_name
            rB = {}
            rB['Status'] = rS
            rB['Reason'] = reason
            rB['PhysicalResourceId'] = physicalResourceId or context.log_stream_name
            rB['StackId'] = event['StackId']
            rB['RequestId'] = event['RequestId']
            rB['LogicalResourceId'] = event['LogicalResourceId']
            rB['NoEcho'] = noEcho
            rB['Data'] = rD
            json_rB = json.dumps(rB)
            print("Response body:\n" + json_rB)
            headers = {
                'content-type' : '',
                'content-length' : str(len(json_rB))
            }
            try:
              response = requests.put(responseUrl,
                                      data=json_rB,
                                      headers=headers)
              print("Status code: " + response.reason)
            except Exception as e:
              print("send(..) failed executing requests.put(..): " + str(e))
      Handler: index.is_license_public
      Runtime: python3.6
      Timeout: 30
      Role: !GetAtt LicenseLambdaExecutionRole.Arn
      Description: !Sub IsLicensePublicInfo Custom prereq checker for Stack ${AWS::StackName}
  # Custom Property to force execution of the IsLicensePublicFunction function
  IsLicensePublicInfo:
    Type: Custom::IsLicensePublicInfo
    Properties:
      ServiceToken: !GetAtt IsLicensePublicFunction.Arn
      DeploymentDataLocation: !Ref DeploymentDataLocation

  IsLicensePublicLambdaFunctionLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub /aws/lambda/${IsLicensePublicFunction}

  DelCert:
    Type: Custom::DelCert
    Properties:
      ServiceToken: !GetAtt DelCertFunction.Arn
      CertName:
          Fn::If:
          - HasSSLCertificate
          - ""
          - !Sub "${AWS::StackName}-selfsigned-cert"
  DelCertLambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: "/"
      Policies:
      - PolicyName: root
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - logs:CreateLogStream
            - logs:PutLogEvents
            Resource: arn:aws:logs:*:*:*
          - Effect: Allow
            Action:
            - iam:DeleteServerCertificate
            Resource: !Sub arn:aws:iam::*:server-certificate/${AWS::StackName}-selfsigned-cert
  # Lambda Function that deletes the self-signed cert on Stack deletion
  # The ELB that uses the cert should already be deleted at this point,
  # because it has the DependsOn= attribute set to the DelCert custom property
  DelCertFunction:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          import boto3
          import cfnresponse
          from time import sleep
          from botocore.exceptions import ClientError
          iam = boto3.client('iam')
          def delcert(event, context):
            if event['RequestType'] == 'Delete':
              certname = event['ResourceProperties']['CertName']
              print "certname: {}".format(certname)
              if len(certname) > 0:
                while True:
                  try:
                    result = iam.delete_server_certificate(ServerCertificateName=certname)
                  except ClientError as e:
                     if e.response['ResponseMetadata']['HTTPStatusCode'] == '200':
                       # delete was successful
                       print e.response
                       break
                     elif e.response['Error']['Code'] == 'NoSuchEntity':
                       # this can happen if the Stack did not fully create, and no Cert was create
                       break
                     else:
                       # the only other possible ErrorCode should be: DeleteConflict
                       # typically when the ELB is still alive, which should not happen
                       # because ELB has the DependsOn= attribute set to the DelCert custom property.
                       # It should be deleted before the objects it depends on
                       print e.response['Error']['Code']
                       sleep(5)
            cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
      Handler: index.delcert
      Runtime: python2.7
      Timeout: 30
      Role: !GetAtt DelCertLambdaExecutionRole.Arn
      Description: !Sub DelCert Custom Property for Stack ${AWS::StackName}

  # create the log Group for Lambda by Cloudformation to ensure
  # it is deleted at termination
  DelCertLambdaFunctionLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub /aws/lambda/${DelCertFunction}


  SNSTopic:
    Condition: SNSCondition
    Type: AWS::SNS::Topic
    Properties:
      Subscription:
        - Endpoint: !Ref OperatorEmail
          Protocol: "email"

  CloudWatchLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      RetentionInDays: 7

  RecoveryAlarmVisual:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmDescription: Trigger a recovery when instance status check fails more than once in 2 minutes.
      Namespace: AWS/EC2
      MetricName: StatusCheckFailed_System
      Statistic: Maximum
      Period: '60'
      EvaluationPeriods: '2'
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Threshold: '1'
      AlarmActions:
        - !Sub "arn:aws:automate:${AWS::Region}:ec2:recover"
        - !If
          - SNSCondition
          - !Ref SNSTopic
          - !Ref AWS::NoValue
      Dimensions:
      - Name: InstanceId
        Value:
          Ref: VisualServices

  RecoveryAlarmStateful:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmDescription: Trigger a recovery when instance status check fails more than once in 2 minutes.
      Namespace: AWS/EC2
      MetricName: StatusCheckFailed_System
      Statistic: Maximum
      Period: '60'
      EvaluationPeriods: '2'
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Threshold: '1'
      AlarmActions:
        - !Sub "arn:aws:automate:${AWS::Region}:ec2:recover"
        - !If
          - SNSCondition
          - !Ref SNSTopic
          - !Ref AWS::NoValue
      Dimensions:
      - Name: InstanceId
        Value:
          Ref: StatefulServices

  RecoveryAlarmProgramming:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmDescription: Trigger a recovery when instance status check fails more than once in 2 minutes.
      Namespace: AWS/EC2
      MetricName: StatusCheckFailed_System
      Statistic: Maximum
      Period: '60'
      EvaluationPeriods: '2'
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Threshold: '1'
      AlarmActions:
        - !Sub "arn:aws:automate:${AWS::Region}:ec2:recover"
        - !If
          - SNSCondition
          - !Ref SNSTopic
          - !Ref AWS::NoValue
      Dimensions:
      - Name: InstanceId
        Value:
          Ref: ProgrammingServices

  RecoveryAlarmController:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmDescription: Trigger a recovery when instance status check fails more than once in 2 minutes.
      Namespace: AWS/EC2
      MetricName: StatusCheckFailed_System
      Statistic: Maximum
      Period: '60'
      EvaluationPeriods: '2'
      ComparisonOperator: GreaterThanOrEqualToThreshold
      Threshold: '1'
      AlarmActions:
        - !Sub "arn:aws:automate:${AWS::Region}:ec2:recover"
        - !If
          - SNSCondition
          - !Ref SNSTopic
          - !Ref AWS::NoValue
      Dimensions:
      - Name: InstanceId
        Value:
          Ref: CASController


  ViyaPlacementGroup:
    Type: AWS::EC2::PlacementGroup

  ELBSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Allow access to the ELB
      VpcId: !Ref VPCID
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: !Ref WebIngressLocation
  AnsibleControllerSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Enables SSH Access to Ansible Controller
      VpcId: !Ref VPCID
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: '22'
          ToPort: '22'
          CidrIp: !Ref AdminIngressLocation
        - IpProtocol: icmp
          FromPort: '-1'
          ToPort: '-1'
          CidrIp: !Ref AdminIngressLocation


  ViyaSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Allow access to all Viya VMs
      VpcId: !Ref VPCID
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: '22'
          ToPort: '22'
          SourceSecurityGroupId: !Ref AnsibleControllerSecurityGroup
        - IpProtocol: tcp
          FromPort: '8008'
          ToPort: '8008'
          SourceSecurityGroupId: !Ref AnsibleControllerSecurityGroup

  ProxySecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Allow access to the Viya HTTPD serer
      VpcId: !Ref VPCID
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: '443'
          ToPort: '443'
          SourceSecurityGroupId: !Ref ELBSecurityGroup


  # open ports between all participants
  # all hosts need to succeed an ssh-keyscan to all other hosts of the deployment
  # and for consul communication
  ViyatoviyaTCPIngress:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      GroupId: !Ref ViyaSecurityGroup
      IpProtocol: tcp
      FromPort: '0'
      ToPort: '65535'
      SourceSecurityGroupId: !Ref ViyaSecurityGroup
  ViyatoviyaUDPIngress:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      GroupId: !Ref ViyaSecurityGroup
      IpProtocol: udp
      FromPort: '0'
      ToPort: '65535'
      SourceSecurityGroupId: !Ref ViyaSecurityGroup


  ElasticLoadBalancer:
    Type: AWS::ElasticLoadBalancing::LoadBalancer
    DependsOn: DelCert
    Properties:
      Subnets:
        - !Ref PublicSubnetID
      SecurityGroups:
        - !Ref ELBSecurityGroup
      AppCookieStickinessPolicy:
        - CookieName: dummy
          PolicyName: AppCookieStickinessPolicy
      Listeners:
        - LoadBalancerPort: 443
          Protocol:
            Fn::If:
            - HasSSLCertificate
            - HTTPS
            - TCP
          InstancePort: 443
          InstanceProtocol:
            Fn::If:
            - HasSSLCertificate
            - HTTPS
            - TCP
          SSLCertificateId:
            Fn::If:
            - HasSSLCertificate
            - Ref: SSLCertificateARN
            - Ref: AWS::NoValue
          PolicyNames:
            - Fn::If:
              - HasSSLCertificate
              - AppCookieStickinessPolicy
              - Ref: AWS::NoValue

      CrossZone: 'true'
      HealthCheck:
        Target: 'TCP:443'
        HealthyThreshold: '2'
        UnhealthyThreshold: '3'
        Interval: '30'
        Timeout: '3'
      Instances:
        - !Ref StatefulServices
        - !Ref VisualServices
        - !Ref ProgrammingServices

  DNSNameEntry:
    Type: AWS::Route53::RecordSet
    Condition: HasDNSEntry
    DependsOn:
    - ElasticLoadBalancer
    Properties:
      HostedZoneId:
        Ref: AWSHostedZoneID
      Name:
        Fn::Sub: ${DomainName}.
      Type: A
      AliasTarget:
        HostedZoneId:
          Fn::GetAtt:
          - ElasticLoadBalancer
          - CanonicalHostedZoneNameID
        DNSName:
          Fn::GetAtt:
          - ElasticLoadBalancer
          - DNSName



  ViyaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ec2.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
      Policies:
#        - PolicyDocument:
#            Version: 2012-10-17
#            Statement:
#              - Action:
#                  - 's3:ListBucket'
#                Resource: !Sub
#                 - 'arn:aws:s3:::${mirror_bucket_name}'
#                 - mirror_bucket_name: !GetAtt LicenseInfo.s3_mirror_bucket
#                Effect: Allow
#              - Action:
#                  - 's3:GetObject'
#                Resource: !Sub
#                  - 'arn:aws:s3:::${mirror_bucket_name}${mirror_bucket_path}*'
#                  - { mirror_bucket_name: !GetAtt LicenseInfo.s3_mirror_bucket,
#                      mirror_bucket_path: !GetAtt LicenseInfo.s3_mirror_path }
#                Effect: Allow
#          PolicyName: aws-mirror-s3-policy
        - PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action:
                  - 's3:GetObject'
                Resource: !Sub 'arn:aws:s3:::${QSS3BucketName}/${QSS3KeyPrefix}*'
                Effect: Allow
          PolicyName: aws-quick-start-s3-policy
        - PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action: 'ssm:GetParameter'
                Resource: !Sub 'arn:aws:ssm:${AWS::Region}:${AWS::AccountId}:parameter/viya-ansiblekey-${AWS::StackName}'
                Effect: Allow
          PolicyName: viya-services-ssm-policy
        - PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action:
                   - 'ec2:DescribeVolumes'
                   - 'ec2:CreateTags'
                Resource: "*"
                Effect: Allow
          PolicyName: viya-services-ec2-policy
        - PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action:
                  - 'logs:CreateLogStream'
                  - 'logs:GetLogEvents'
                  - 'logs:PutLogEvents'
                  - 'logs:DescribeLogGroups'
                  - 'logs:DescribeLogStreams'
                  - 'logs:PutRetentionPolicy'
                  - 'logs:PutMetricFilter'
                  - 'logs:CreateLogGroup'
                Resource: !Sub
                  - arn:${Partition}:logs:${AWS::Region}:${AWS::AccountId}:log-group:${CloudWatchLogGroup}:*
                  - Partition: !If
                      - GovCloudCondition
                      - aws-us-gov
                      - aws
                Effect: Allow
          PolicyName: viya-services-cloudwatch-logs-policy
  ViyaProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: /
      Roles:
        - !Ref ViyaRole

  VisualServices:
    Type: AWS::EC2::Instance
    CreationPolicy:
      ResourceSignal:
        Count: 1
        Timeout: 'PT10M'
    Metadata:
      'AWS::CloudFormation::Authentication':
        S3AccessCreds:
          type: S3
          roleName: !Ref ViyaRole
          buckets:
            - !Ref QSS3BucketName
      'AWS::CloudFormation::Init':
        configSets:
          quickstart:
            - install
        install:
          commands:
            01-getkey:
              command:
                Fn::Sub: |
                  #!/bin/bash
                  KEY=dummy
                  # wait until the key is available (the ansible controller puts it there)
                  TRIES=0
                  until [[ ! "$KEY" = "dummy" || $TRIES -gt 10 ]]; do
                     KEY=$(aws ssm get-parameter --region "${AWS::Region}" --name "viya-ansiblekey-${AWS::StackName}" --query Parameter.Value --output text)
                     if [[ $KEY = *"error"* ]]; then
                        sleep 5
                        let TRIES++
                     else
                        sleep 1
                     fi
                  done
                  if [ $TRIES -gt 10 ]; then
                     echo "Error - could not obtain key from ssm."
                     exit 1
                  fi
                  echo "$KEY" | su ec2-user bash -c 'tee -a ~/.ssh/authorized_keys'
    Properties:
      KeyName: !Ref KeyPairName
      ImageId: !FindInMap
         - AWSAMIRegionMap
         - !Ref AWS::Region
         - RHEL74HVM
      SubnetId: !Ref PrivateSubnetID
      IamInstanceProfile: !Ref ViyaProfile
      InstanceType: r4.4xlarge
      EbsOptimized: true
      PlacementGroupName: !Ref ViyaPlacementGroup
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: '20'
            VolumeType: gp2
            DeleteOnTermination: true
        - DeviceName: /dev/sdg
          Ebs:
            VolumeSize: '50'
            VolumeType: gp2
            DeleteOnTermination: true
            Encrypted: true
      SecurityGroupIds:
        - !Ref ViyaSecurityGroup
        - !Ref ProxySecurityGroup
      Tags:
        - Key: Name
          Value: !Sub "${AWS::StackName} Visual Services"
      UserData:
        Fn::Base64:
          Fn::Sub: |
            #!/bin/bash
            export PATH=$PATH:/usr/local/bin
            curl -O https://bootstrap.pypa.io/get-pip.py && python get-pip.py &> /dev/null
            pip install awscli --ignore-installed six &> /dev/null
            easy_install https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-latest.tar.gz

            cfn-init --stack ${AWS::StackName} --resource VisualServices --configsets quickstart --region ${AWS::Region}
            # Signal the status from cfn-init
            cfn-signal -e $? --stack ${AWS::StackName} --resource VisualServices --region ${AWS::Region}
  ProgrammingServices:
    Type: AWS::EC2::Instance
    CreationPolicy:
      ResourceSignal:
        Count: 1
        Timeout: 'PT10M'
    Metadata:
      'AWS::CloudFormation::Authentication':
        S3AccessCreds:
          type: S3
          roleName: !Ref ViyaRole
          buckets:
            - !Ref QSS3BucketName
      'AWS::CloudFormation::Init':
        configSets:
          quickstart:
            - install
        install:
          commands:
            01-getkey:
              command:
                Fn::Sub: |
                  #!/bin/bash
                  KEY=dummy
                  # wait until the key is available (the ansible controller puts it there)
                  TRIES=0
                  until [[ ! "$KEY" = "dummy" || $TRIES -gt 10 ]]; do
                     KEY=$(aws ssm get-parameter --region "${AWS::Region}" --name "viya-ansiblekey-${AWS::StackName}" --query Parameter.Value --output text)
                     if [[ $KEY = *"error"* ]]; then
                        sleep 5
                        let TRIES++
                     else
                        sleep 1
                     fi
                  done
                  if [[ $TRIES -gt 10 ]]; then
                     echo "Error - could not obtain key from ssm."
                     exit 1
                  fi
                  echo "$KEY" | su ec2-user bash -c 'tee -a ~/.ssh/authorized_keys'

    Properties:
      KeyName: !Ref KeyPairName
      ImageId: !FindInMap
        - AWSAMIRegionMap
        - !Ref AWS::Region
        - RHEL74HVM
      SubnetId: !Ref PrivateSubnetID
      IamInstanceProfile: !Ref ViyaProfile
      InstanceType: r4.2xlarge
      EbsOptimized: true
      PlacementGroupName: !Ref ViyaPlacementGroup
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: '20'
            VolumeType: gp2
            DeleteOnTermination: true
        - DeviceName: /dev/sdg
          Ebs:
            VolumeSize: '50'
            VolumeType: gp2
            DeleteOnTermination: true
            Encrypted: true
      SecurityGroupIds:
        - !Ref ProxySecurityGroup
        - !Ref ViyaSecurityGroup
      Tags:
        - Key: Name
          Value: !Sub "${AWS::StackName} Programming Services"
      UserData:
        Fn::Base64:
          Fn::Sub: |
            #!/bin/bash
            export PATH=$PATH:/usr/local/bin
            curl -O https://bootstrap.pypa.io/get-pip.py && python get-pip.py &> /dev/null
            pip install awscli --ignore-installed six &> /dev/null
            easy_install https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-latest.tar.gz
            cfn-init --stack ${AWS::StackName} --resource ProgrammingServices --configsets quickstart --region ${AWS::Region}
            # Signal the status from cfn-init
            cfn-signal -e $? --stack ${AWS::StackName} --resource ProgrammingServices --region ${AWS::Region}

  StatefulServices:
    Type: AWS::EC2::Instance
    CreationPolicy:
      ResourceSignal:
        Count: 1
        Timeout: 'PT10M'
    Metadata:
      'AWS::CloudFormation::Authentication':
        S3AccessCreds:
          type: S3
          roleName: !Ref ViyaRole
          buckets:
            - !Ref QSS3BucketName
      'AWS::CloudFormation::Init':
        configSets:
          quickstart:
            - install
        install:
          commands:
            01-getkey:
              command:
                Fn::Sub: |
                  #!/bin/bash
                  KEY=dummy
                  # wait until the key is available (the ansible controller puts it there)
                  TRIES=0
                  until [[ ! "$KEY" = "dummy" || $TRIES -gt 10 ]]; do
                     KEY=$(aws ssm get-parameter --region "${AWS::Region}" --name "viya-ansiblekey-${AWS::StackName}" --query Parameter.Value --output text)
                     if [[ $KEY = *"error"* ]]; then
                        sleep 5
                        let TRIES++
                     else
                        sleep 1
                     fi
                  done
                  if [[ $TRIES -gt 10 ]]; then
                     echo "Error - could not obtain key from ssm."
                     exit 1
                  fi
                  echo "$KEY" | su ec2-user bash -c 'tee -a ~/.ssh/authorized_keys'
    Properties:
      KeyName: !Ref KeyPairName
      ImageId: !FindInMap
        - AWSAMIRegionMap
        - !Ref AWS::Region
        - RHEL74HVM
      SubnetId: !Ref PrivateSubnetID
      IamInstanceProfile: !Ref ViyaProfile
      InstanceType: r4.2xlarge
      EbsOptimized: true
      PlacementGroupName: !Ref ViyaPlacementGroup
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: '20'
            VolumeType: gp2
            DeleteOnTermination: true
        - DeviceName: /dev/sdg
          Ebs:
            VolumeSize: '50'
            VolumeType: gp2
            DeleteOnTermination: true
            Encrypted: true
      SecurityGroupIds:
        - !Ref ViyaSecurityGroup
        - !Ref ProxySecurityGroup
      Tags:
        - Key: Name
          Value: !Sub "${AWS::StackName} Stateful Services"
      UserData:
        Fn::Base64:
          Fn::Sub: |
            #!/bin/bash
            export PATH=$PATH:/usr/local/bin
            curl -O https://bootstrap.pypa.io/get-pip.py && python get-pip.py &> /dev/null
            pip install awscli --ignore-installed six &> /dev/null
            easy_install https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-latest.tar.gz
            cfn-init --stack ${AWS::StackName} --resource StatefulServices --configsets quickstart --region ${AWS::Region}
            # Signal the status from cfn-init
            cfn-signal -e $? --stack ${AWS::StackName} --resource StatefulServices --region ${AWS::Region}



  CASController:
    Type: AWS::EC2::Instance
    CreationPolicy:
      ResourceSignal:
        Count: 1
        Timeout: 'PT10M'
    Metadata:
      'AWS::CloudFormation::Authentication':
        S3AccessCreds:
          type: S3
          roleName: !Ref ViyaRole
          buckets:
            - !Ref QSS3BucketName
      'AWS::CloudFormation::Init':
        configSets:
          quickstart:
            - install
        install:
          commands:
            01-getkey:
              command:
                Fn::Sub: |
                  #!/bin/bash
                  KEY=dummy
                  # wait until the key is available (the ansible controller puts it there)
                  TRIES=0
                  until [[ ! "$KEY" = "dummy" || $TRIES -gt 10 ]]; do
                     KEY=$(aws ssm get-parameter --region "${AWS::Region}" --name "viya-ansiblekey-${AWS::StackName}" --query Parameter.Value --output text)
                     if [[ $KEY = *"error"* ]]; then
                        sleep 5
                        let TRIES++
                     else
                        sleep 1
                     fi
                  done
                  if [[ $TRIES -gt 10 ]]; then
                     echo "Error - could not obtain key from ssm."
                     exit 1
                  fi
                  echo "$KEY" | su ec2-user bash -c 'tee -a ~/.ssh/authorized_keys'

    Properties:
      KeyName: !Ref KeyPairName
      ImageId: !FindInMap
        - AWSAMIRegionMap
        - !Ref AWS::Region
        - RHEL74HVM
      SubnetId: !Ref PrivateSubnetID
      IamInstanceProfile: !Ref ViyaProfile
      # transform "Nxlarge (N cores)" to "r4.Nxlarge"
      InstanceType: !Join
        - '.'
        - - r4 # !Ref CASInstanceType
          - !GetAtt LicenseInfo.NodeInstanceSize
      EbsOptimized: true
      PlacementGroupName: !Ref ViyaPlacementGroup
      SecurityGroupIds:
        - !Ref ViyaSecurityGroup

      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName} CAS Controller
      UserData:
        Fn::Base64:
          Fn::Sub: |
            #!/bin/bash
            export PATH=$PATH:/usr/local/bin
            curl -O https://bootstrap.pypa.io/get-pip.py && python get-pip.py &> /dev/null
            pip install awscli --ignore-installed six &> /dev/null
            easy_install https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-latest.tar.gz
            cfn-init --stack ${AWS::StackName} --resource CASController --configsets quickstart --region ${AWS::Region}
            # Signal the status from cfn-init
            cfn-signal -e $? --stack ${AWS::StackName} --resource CASController --region ${AWS::Region}


  CASViyaVolume:
    Type: AWS::EC2::Volume
    Properties:
      Size: 50
      VolumeType: gp2
      Encrypted: true
      AvailabilityZone: !GetAtt CASController.AvailabilityZone
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName} CAS Controller Viya Install

  CASViyaAttachment:
    Type: AWS::EC2::VolumeAttachment
    Properties:
      Device: /dev/sdg
      InstanceId: !Ref CASController
      VolumeId: !Ref CASViyaVolume


  CASLibVolume:
    Type: AWS::EC2::Volume
    Properties:
      Size: !GetAtt LicenseInfo.CASLibSize
      VolumeType: gp2
      Encrypted: true
      AvailabilityZone: !GetAtt CASController.AvailabilityZone
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName} CAS Controller CASLib

  CASLibAttachment:
    Type: AWS::EC2::VolumeAttachment
    Properties:
      Device: /dev/sdl
      InstanceId: !Ref CASController
      VolumeId: !Ref CASLibVolume


  CASCacheVolume:
    #Condition: IsNotI3
    Type: AWS::EC2::Volume
    Properties:
      Size: !GetAtt LicenseInfo.CASCacheSize
      VolumeType: gp2
      Encrypted: true
      AvailabilityZone: !GetAtt CASController.AvailabilityZone
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName} CAS Controller CAS Cache

  CASCacheAttachment:
    #Condition: IsNotI3
    Type: AWS::EC2::VolumeAttachment
    Properties:
      Device: /dev/sdd
      InstanceId: !Ref CASController
      VolumeId: !Ref CASCacheVolume

  AnsiblePublicKey:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub 'viya-ansiblekey-${AWS::StackName}'
      Description: !Sub 'viya-ansiblekey-${AWS::StackName}'
      Type: String
      Value: dummy

  AnsibleControllerRole:
    Type: AWS::IAM::Role
    Properties:
      Policies:
        - PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action:
                  - "cloudformation:DescribeStackResources"
                  - "cloudformation:DescribeStacks"
                Resource:
                  - !Sub "arn:aws:cloudformation:${AWS::Region}:${AWS::AccountId}:stack/${AWS::StackName}*/*"
                Effect: Allow
          PolicyName: ansiblecontroller-cfn-policy
        - PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action:
                  - "acm:DescribeCertificate"
                Resource:
                  - "arn:aws:acm:*:*:certificate/*"
                Effect: Allow
          PolicyName: ansiblecontroller-acm-policy
        - PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action:
                  - 'SNS:Publish'
                Resource: "*"
                Effect: Allow
          PolicyName: ansiblecontroller-sns-policy
        - PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action:
                  - 's3:ListBucket'
                Resource:
                  - !Sub 'arn:aws:s3:::${QSS3BucketName}'
                Effect: Allow
              - Action:
                  - 's3:GetObject'
                Resource:
                  - !Sub 'arn:aws:s3:::${QSS3BucketName}/*'

                Effect: Allow
          PolicyName: aws-quick-start-s3-policy
        - PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action:
                  - 's3:getObject'
                Resource:
                  - !Sub 'arn:aws:s3:::${DeploymentDataLocation}'
                Effect: Allow
          PolicyName: viya-playbook-s3-policy
#        - PolicyDocument:
#            Version: 2012-10-17
#            Statement:
#              - Action:
#                  - 's3:ListBucket'
#                Resource: !Sub
#                 - 'arn:aws:s3:::${mirror_bucket_name}'
#                 - mirror_bucket_name: !GetAtt LicenseInfo.s3_mirror_bucket
#                Effect: Allow
#              - Action:
#                  - 's3:GetObject'
#                Resource: !Sub
#                  - 'arn:aws:s3:::${mirror_bucket_name}${mirror_bucket_path}*'
#                  - { mirror_bucket_name: !GetAtt LicenseInfo.s3_mirror_bucket,
#                      mirror_bucket_path: !GetAtt LicenseInfo.s3_mirror_path }
#                Effect: Allow
#          PolicyName: aws-mirror-s3-policy
        - PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action:
                  - 'ssm:PutParameter'
                Resource:
                  - !Sub 'arn:aws:ssm:${AWS::Region}:${AWS::AccountId}:parameter/viya-ansiblekey-${AWS::StackName}'
                Effect: Allow
          PolicyName: ansible-controller-ssm-policy
        - PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action:
                  - 'ec2:AssociateAddress'
                  - 'ec2:DescribeAddresses'
                  - 'ec2:DescribeInstances'
                  - 'ec2:RunInstances'
                  - 'ec2:AttachVolume'
                  - 'ec2:CreateTags'
                  - 'elasticloadbalancing:DescribeLoadBalancers'
                  - 'elasticloadbalancing:DeleteLoadBalancerListeners'
                  - 'elasticloadbalancing:CreateLoadBalancerListeners'
                  - 'elasticloadbalancing:SetLoadBalancerPoliciesOfListener'
                Resource:
                  - '*'
                Effect: Allow
          PolicyName: ansiblecontroller-ec2-policy
        - PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action:
                  - 'iam:uploadServerCertificate'
                  - 'iam:listServerCertificates'
                Resource:
                  - '*'
                Effect: Allow
              - Action:
                  - 'iam:PassRole'
                Resource:
                  - !Sub arn:aws:iam::${AWS::AccountId}:role/${ViyaRole}
                Effect: Allow
          PolicyName: ansiblecontroller-iam-policy
        - PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action:
                  - 'route53:GetHostedZone'
                  - 'route53:ListResourceRecordSets'
                Resource:
                  - '*'
                Effect: Allow
          PolicyName: ansiblecontroller-route53-policy
        - PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Action:
                  - 'logs:CreateLogStream'
                  - 'logs:GetLogEvents'
                  - 'logs:PutLogEvents'
                  - 'logs:DescribeLogGroups'
                  - 'logs:DescribeLogStreams'
                  - 'logs:PutRetentionPolicy'
                  - 'logs:PutMetricFilter'
                  - 'logs:CreateLogGroup'
                Resource: !Sub
                  - arn:${Partition}:logs:${AWS::Region}:${AWS::AccountId}:log-group:${CloudWatchLogGroup}:*
                  - Partition: !If
                      - GovCloudCondition
                      - aws-us-gov
                      - aws
                Effect: Allow
          PolicyName: ansiblecontroller-cloudwatch-logs-policy
      Path: /
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - 'sts:AssumeRole'
            Principal:
              Service:
                - ec2.amazonaws.com
            Effect: Allow
        Version: 2012-10-17
  AnsibleControllerProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Roles:
        - !Ref AnsibleControllerRole
      Path: /
  AnsibleControllerEIP:
    Type: AWS::EC2::EIP
    Properties:
      Domain: vpc
  AnsibleController:
    Type: AWS::EC2::Instance
    CreationPolicy:
      ResourceSignal:
        Count: 1
        Timeout: 'PT3H30M'
    Metadata:
      'AWS::CloudFormation::Authentication':
        S3AccessCreds:
          type: S3
          roleName: !Ref AnsibleControllerRole
          buckets:
            - !Ref QSS3BucketName
            - !Ref DeploymentDataLocation
      'AWS::CloudFormation::Init':
        configSets:
          quickstart:
            - config
            - sasprep
        config:
          files:
            /tmp/ansiblecontroller_prereqs.sh:
              source: !Sub
                - https://${QSS3BucketName}.${QSS3Region}.amazonaws.com/${QSS3KeyPrefix}scripts/ansiblecontroller_prereqs.sh
                - QSS3Region: !If
                    - GovCloudCondition
                    - s3-us-gov-west-1
                    - s3
              mode: '000550'
              owner: root
              group: root
              authentication: S3AccessCreds
            /tmp/bastion_bootstrap.sh:
              source: !Sub
                - https://${QSS3BucketName}.${QSS3Region}.amazonaws.com/${QSS3KeyPrefix}scripts/bastion_bootstrap.sh
                - QSS3Region: !If
                    - GovCloudCondition
                    - s3-us-gov-west-1
                    - s3
              mode: '000550'
              owner: root
              group: root
              authentication: S3AccessCreds
            /tmp/cloudwatch.conf:
              source: !Sub
                - https://${QSS3BucketName}.${QSS3Region}.amazonaws.com/${QSS3KeyPrefix}scripts/cloudwatch.ansiblecontroller.conf
                - QSS3Region: !If
                    - GovCloudCondition
                    - s3-us-gov-west-1
                    - s3
              mode: '000440'
              owner: root
              group: root
              authentication: S3AccessCreds
              context:
                LogGroup: !Ref CloudWatchLogGroup

          commands:
            01-bootstrap:
              command: /tmp/bastion_bootstrap.sh --enable false
            02-cloudwatch:
              command: >-
                sed -i 's/{instance_id}/ansible-controller-commands.log/' /etc/awslogs/awslogs.conf;
                cat /tmp/cloudwatch.conf >> /etc/awslogs/awslogs.conf;
                service awslogs restart
            03-prereqs:
              command: /tmp/ansiblecontroller_prereqs.sh
        sasprep:
          files:
            /home/ec2-user/deployment-scripts/install.sh:
              source: !Sub
                - https://${QSS3BucketName}.${QSS3Region}.amazonaws.com/${QSS3KeyPrefix}scripts/install.sh
                - QSS3Region: !If
                    - GovCloudCondition
                    - s3-us-gov-west-1
                    - s3
              mode: '000500'
              owner: ec2-user
              group: ec2-user
              authentication: S3AccessCreds
              context:
                SASUserPass: !Ref SASUserPass
                SASAdminPass: !Ref SASAdminPass
                LogGroup: !Ref CloudWatchLogGroup
                SNSTopic: !If [SNSCondition, !Ref SNSTopic, ""]
                AWSRegion: !Ref AWS::Region
                KeyPairName: !Ref KeyPairName
                AnsibleControllerIP: !Ref AnsibleControllerEIP
                NumWorkers: !GetAtt LicenseInfo.NumWorkers
                CloudFormationStack: !Ref AWS::StackName
                CloudWatchLogs: !Sub "https://console.aws.amazon.com/cloudwatch/home?region=${AWS::Region}#logStream:group=${CloudWatchLogGroup}"
                SSLCertificateARN: !Ref SSLCertificateARN
                DomainName: !Ref DomainName
                HostedZoneID: !If [HasDNSEntry, !Ref AWSHostedZoneID, ""]
                S3FileRoot: !Sub "${QSS3BucketName}/${QSS3KeyPrefix}"
                DeploymentDataLocation: !Ref DeploymentDataLocation
                RAIDScript: !Sub ${QSS3BucketName}/${QSS3KeyPrefix}scripts/disks_ephemeral.sh
                DeploymentMirror: "" #!Ref DeploymentMirror
                ViyaVersion: !GetAtt LicenseInfo.ViyaVersion

            /home/ec2-user/deployment-scripts/create.mirror.yml:
              source: !Sub
                - https://${QSS3BucketName}.${QSS3Region}.amazonaws.com/${QSS3KeyPrefix}playbooks/create.mirror.yml
                - QSS3Region: !If
                    - GovCloudCondition
                    - s3-us-gov-west-1
                    - s3
              mode: '000500'
              owner: ec2-user
              group: ec2-user
              authentication: S3AccessCreds
              context:
                AWSRegion: !Ref AWS::Region
                #S3MirrorLocation: !Ref DeploymentMirror


            /home/ec2-user/deployment-scripts/recover_cascontroller.sh:
              source: !Sub
                - https://${QSS3BucketName}.${QSS3Region}.amazonaws.com/${QSS3KeyPrefix}scripts/recover_cascontroller.sh
                - QSS3Region: !If
                    - GovCloudCondition
                    - s3-us-gov-west-1
                    - s3
              mode: '000500'
              owner: ec2-user
              group: ec2-user
              authentication: S3AccessCreds
              context:
                Stack: !Ref AWS::StackName
                AWSRegion: !Ref AWS::Region
                ImageId: !FindInMap
                   - AWSAMIRegionMap
                   - !Ref AWS::Region
                   - RHEL74HVM
                KeyName: !Ref KeyPairName
                SubnetId: !Ref PrivateSubnetID
                IamInstanceProfile: !Ref ViyaProfile
                InstanceType: !Join
                  - '.'
                  - - r4 # !Ref CASInstanceType
                    - !GetAtt LicenseInfo.NodeInstanceSize
                PlacementGroupName: !Ref ViyaPlacementGroup
                SecurityGroupIds: !Ref ViyaSecurityGroup
                SASUserPass: !Ref SASUserPass
                SASAdminPass: !Ref SASAdminPass
                RAIDScript: !Sub ${QSS3BucketName}/${QSS3KeyPrefix}scripts/disks_ephemeral.sh

            /tmp/ansible.cfg:
              source: !Sub
                - https://${QSS3BucketName}.${QSS3Region}.amazonaws.com/${QSS3KeyPrefix}playbooks/ansible.cfg
                - QSS3Region: !If
                    - GovCloudCondition
                    - s3-us-gov-west-1
                    - s3
              mode: '000444'
              owner: ec2-user
              group: ec2-user
              authentication: S3AccessCreds
            /tmp/ansible.update.inventory.yml:
              source: !Sub
                - https://${QSS3BucketName}.${QSS3Region}.amazonaws.com/${QSS3KeyPrefix}playbooks/update.inventory.${ViyaVersion}.yml
                - QSS3Region: !If
                    - GovCloudCondition
                    - s3-us-gov-west-1
                    - s3
                  ViyaVersion: !GetAtt LicenseInfo.ViyaVersion
              mode: '000444'
              owner: ec2-user
              group: ec2-user
              authentication: S3AccessCreds
            /tmp/ansible.pre.deployment.yml:
              source: !Sub
                - https://${QSS3BucketName}.${QSS3Region}.amazonaws.com/${QSS3KeyPrefix}playbooks/pre.deployment.yml
                - QSS3Region: !If
                    - GovCloudCondition
                    - s3-us-gov-west-1
                    - s3
              mode: '000444'
              owner: ec2-user
              group: ec2-user
              authentication: S3AccessCreds
            /tmp/ansible.post.deployment.yml:
              source: !Sub
                - https://${QSS3BucketName}.${QSS3Region}.amazonaws.com/${QSS3KeyPrefix}playbooks/post.deployment.yml
                - QSS3Region: !If
                    - GovCloudCondition
                    - s3-us-gov-west-1
                    - s3
              mode: '000444'
              owner: ec2-user
              group: ec2-user
              authentication: S3AccessCreds
            /tmp/ansible.update.config.yml:
              source: !Sub
                - https://${QSS3BucketName}.${QSS3Region}.amazonaws.com/${QSS3KeyPrefix}playbooks/update.config.yml
                - QSS3Region: !If
                    - GovCloudCondition
                    - s3-us-gov-west-1
                    - s3
              mode: '000444'
              owner: ec2-user
              group: ec2-user
              authentication: S3AccessCreds
            /tmp/openldapfiles.txt:
              source: !Sub
                - https://${QSS3BucketName}.${QSS3Region}.amazonaws.com/${QSS3KeyPrefix}openldap/files.txt
                - QSS3Region: !If
                    - GovCloudCondition
                    - s3-us-gov-west-1
                    - s3
              mode: '000444'
              owner: ec2-user
              group: ec2-user
              authentication: S3AccessCreds
          commands:
            01-install:
              command: sudo su -l ec2-user -c "./deployment-scripts/install.sh"
            02-post-install:
              command: |-
                chmod +w /home/ec2-user/deployment-scripts/install.sh
                sed -i  's/ADMINPASS=$.*/ADMINPASS="xxxx"/' /home/ec2-user/deployment-scripts/install.sh
                sed -i  's/USERPASS=$.*/USERPASS="xxxx"/' /home/ec2-user/deployment-scripts/install.sh
                chmod -w /home/ec2-user/deployment-scripts/install.sh
    Properties:
      KeyName: !Ref KeyPairName
      SubnetId: !Ref PublicSubnetID
      IamInstanceProfile: !Ref AnsibleControllerProfile
      ImageId: !FindInMap
        - AWSAMIRegionMap
        - !Ref AWS::Region
        - AMZNLINUXHVM
      SecurityGroupIds:
        - !Ref AnsibleControllerSecurityGroup
      InstanceType: t2.small
      Tags:
        - Key: Name
          Value: !Sub "${AWS::StackName} Ansible Controller"
      UserData:
        Fn::Base64:
          Fn::Sub: |
            #!/bin/bash
            export PATH=$PATH:/usr/local/bin:/opt/aws/bin
            pip install awscli --ignore-installed six &> /dev/null
            # remove pre-installed cfn bootstrap utilities
            yum -y remove aws-cfn-bootstrap
            hash -d /opt/aws/bin/cfn-init
            # install latest cfn bootstrap utilities
            easy_install https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-latest.tar.gz
            CLOUDWATCHGROUP=${CloudWatchLogGroup}
            EIP_LIST=${AnsibleControllerEIP}
            cfn-init --stack ${AWS::StackName} --resource AnsibleController --configsets quickstart --region ${AWS::Region}
            # Signal the status from cfn-init
            cfn-signal -e $? --stack ${AWS::StackName} --resource AnsibleController --region ${AWS::Region}

Outputs:
  SASHome:
    Description: SAS Viya launch page for SAS solutions and SAS Environment Manager
    Value: !Join
      - ''
      - - 'https://'
        - Fn::If:
          - HasDNSEntry
          - !Ref DomainName
          - !GetAtt
            - ElasticLoadBalancer
            - DNSName
        - !GetAtt LicenseInfo.SASHomePath
  SASStudio:
    Description: SAS Studio
    Value: !Join
      - ''
      - - 'https://'
        - Fn::If:
          - HasDNSEntry
          - !Ref DomainName
          - !GetAtt
            - ElasticLoadBalancer
            - DNSName
        - !GetAtt LicenseInfo.SASStudioPath
  AnsibleControllerIP:
    Description: Ansible Controller IP address
    Value: !Ref AnsibleControllerEIP
  CloudWatchLogs:
    Description: CloudWatch Logs.
    # e.g.     https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logStream:group=qs-viya-CloudWatchLogGroup-1KIGMD9DKO4RH
    Value: !Join
      - ''
      - - 'https://console.aws.amazon.com/cloudwatch/home?region='
        - !Ref AWS::Region
        - "#logStream:group="
        - !Ref CloudWatchLogGroup
